{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa70ee8f-c891-4f05-be5c-e2b9d74be685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08bacb9-a725-4c50-a294-a02fb61d89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Freezing All Layers (Feature Extraction)\n",
    "# The model uses VGG16 as a fixed feature extractor. Only the fully connected layers (FC) are trained.\n",
    "# When the new dataset is small and similar to the original dataset (e.g., using ImageNet-trained model for animal classification).\n",
    "\n",
    "# Load VGG16 without the top classification layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze all layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')  # 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e0d03-a87d-41c4-b408-c0c2fba9ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Freezing Some Layers (Fine-tune Higher Layers)\n",
    "# Lower layers (edge detectors) are frozen. Higher layers (task-specific) are fine-tuned.\n",
    "# When dataset is moderately sized, and similar features can be reused while learning new patterns.\n",
    "\n",
    "# Unfreeze top few layers for fine-tuning\n",
    "for layer in base_model.layers[:-5]:  # Freeze all except last 5 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile again (after changing trainable parameters)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print trainable layers\n",
    "for layer in model.layers[0].layers:\n",
    "    print(layer.name, \"Trainable:\", layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c84b6d-70ad-4483-9d1e-fcb3e1520481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Unfreezing All Layers (Full Fine-Tuning)\n",
    "# Initially freeze layers, train on new data. Then unfreeze some or all layers and retrain with a lower learning rate.\n",
    "# When dataset is large and different from original (e.g., training on medical X-rays instead of ImageNet).\n",
    "\n",
    "# Unfreeze all layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Use a very small learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train again with more epochs\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae14d51-4243-4dd5-ae62-d9abc138dc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
