{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca931da-b4d9-45db-b603-0ad1176b4e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain: ./images/train  # Path to training images\\nval: ./images/val      # Path to validation images\\n\\nnc: 2  # Number of classes\\nnames: [\"cat\", \"dog\"]\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! pip install ultralytics opencv-python tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87348c9-9c42-46fc-b4db-727e208cbe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2c584-b837-4a4b-9224-7aad4108f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the Dataset\n",
    "\n",
    "'''\n",
    "YOLO requires the dataset in YOLO format:\n",
    "\n",
    "images/train/ → Training images\n",
    "images/val/ → Validation images\n",
    "labels/train/ → Annotation files for training\n",
    "labels/val/ → Annotation files for validation\n",
    "\n",
    "Each annotation file (.txt) follows this format: <class_id> <x_center> <y_center> <width> <height>\n",
    "\n",
    "e.g., \n",
    "0 0.45 0.55 0.30 0.40\n",
    "1 0.60 0.70 0.20 0.30\n",
    "\n",
    "Explanation:\n",
    "class_id → Class index (e.g., 0 = cat, 1 = dog).\n",
    "x_center, y_center → Normalized coordinates of the bounding box.\n",
    "width, height → Normalized width and height of the bounding box.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61813a15-dc94-4457-b5b4-07708860965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml\n",
    "\n",
    "'''\n",
    "train: ./images/train  # Path to training images\n",
    "val: ./images/val      # Path to validation images\n",
    "\n",
    "nc: 2  # Number of classes\n",
    "names: [\"cat\", \"dog\"]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f90a9f-7703-46b3-8d74-b711c1955bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train YOLO on the Custom Dataset\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "# Train the model on the custom dataset\n",
    "model.train(data=\"data.yaml\", epochs=50, imgsz=640, batch=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ce2b9-088d-44f7-90cc-906492dee418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "metrics = model.val()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e13f504-49c3-421e-98e0-8cbafba8a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test YOLO on New Images\n",
    "results = model(\"test_image.jpg\")  # Run detection\n",
    "for result in results:\n",
    "    result.show()  # Display detected objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503439ea-723e-4871-b9c8-2a0c59ec455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save & Export the Model\n",
    "model.export(format=\"onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
